### About Me

Dr. Juntao Li is now an associate professor at [School of Computer Science & Technology, Soochow University](http://scst.suda.edu.cn/). Before that, he obtained the doctoral degree from Peking University in 2020, supervised by [Dr. Rui Yan](https://scholar.google.com.hk/citations?user=eLw6g-UAAAAJ&hl=zh-CN), Prof. [Dongyan Zhao](https://scholar.google.com/citations?user=lhR8-68AAAAJ&hl=zh-CN), and Prof. Dongmin Chen. 



**I am leading a research group on language models. We are dedicated to building application-oriented, open-source, large-size language models with transparency, reusability, and low-cost deployment. More details can be found at [OpenNLG](https://opennlg.cn/)**
```

### 1. Contact
ljtsudanlp@gmail.com<br>
ljt@suda.edu.cn

### 2. Research Interests and Selected Papers
(<sup>'*'</sup> = equal contribution, <sup>'#'</sup> = corresponding author )

#### 2.1 Pretrained Language Models 
* (**OpenBA: An Open-sourced 15B Bilingual Asymmetric seq2seq Model Pre-trained from Scratch**)[[Report]](https://arxiv.org/pdf/2309.10706.pdf)[[Model & Code]](https://github.com/OpenNLG/openBA)
* [**EMNLP-23**] Yi Su, Yixin Ji, **Juntao Li<sup>#</sup>**, Hai Ye, Min Zhang. Beware of Model Collapse! Fast and Stable Test-time Adaptation for Robust Question Answering. **EMNLP 2023**. [[pdf]]()(**CCF B**)
* [**EMNLP-23**] Chuyue Zhou, WangJie You, **Juntao Li<sup>#</sup>**, Jing Ye, Kehai Chen, Min Zhang. INFORM : Information eNtropy based multi-step reasoning FOR large language Models. **EMNLP 2023**. [[pdf]]()(**CCF B**)
* [**EMNLP-23**] Yixin Ji, Jikai Wang, **Juntao Li<sup>#</sup>**, Hai Ye, Min Zhang. Isotropic Representation Can Improve Zero-Shot Cross-Lingual Transfer on Multilingual Language Models. **EMNLP 2023 Findings**. [[pdf]]()
* [**EMNLP-23**] Zhaochen Su, **Juntao Li<sup>#</sup>**, Zikang Zhang, Zihan Zhou, Min Zhang . Efficient Continue Training of Temporal Language Model with Structural Information. **EMNLP 2023 Findings**. [[pdf]]()
* [**EMNLP-23**] Haoke Zhang, Yue Wang, **Juntao Li<sup>#</sup>**, Xiabing Zhou, Min Zhang. G-SPEED: General SParse Efficient Editing MoDel. **EMNLP 2023 Findings**. [[pdf]]()
* [**EMNLP-23**] Pei Guo, yisheng xiao, **Juntao Li<sup>#</sup>**, Yixin Ji, Min Zhang. Isotropy-Enhanced Conditional Masked Language Models. **EMNLP 2023 Findings**. [[pdf]]()
* [**EMNLP-23**] Lei Geng, Xu Yan, Ziqiang Cao, Juntao Li, Wenjie Li, Sujian Li, Xinjie Zhou, Yang Yang, Jun Zhang. KBioXLM: A Knowledge-anchored Biomedical Multilingual Pretrained Language Model. **EMNLP 2023 Findings**. [[pdf]]()
* [**AI J**] Yue Wang, Lijun Wu, **Juntao Li<sup>#</sup>**, Xiaobo Liang, Min Zhang. Are BERT Families Zero-Shot Learners? A Study on Their Potential and Limitations. **Artificial Intelligence**. [[pdf]](https://www.sciencedirect.com/science/article/pii/S0004370223000991)[[code]](https://github.com/wangyuenlp/bert_%20family_zero_shot)(**CCF A**)
* [**ACL-23**] Yixin Ji, Jikai Wang, **Juntao Li<sup>#</sup>**, Qiang Chen, Wenliang Chen and Min Zhang. Early Exit with Disentangled Representation and Equiangular Tight Frame. [[pdf]](https://aclanthology.org/2023.findings-acl.889.pdf)[[code]](https://github.com/Jikai0Wang/DREE) **ACL 2023 Findings** 
* [**EMNLP-22**] Zhaochen Su<sup>\*</sup>, Zecheng Tang<sup>*</sup>, Xinyan Guan, **Juntao Li<sup>#</sup>**, Lijun Wu, Min Zhang. Improving Temporal Generalization of Pre-trained Language Models with Lexical Semantic Change. [[pdf]](https://arxiv.org/pdf/2210.17127.pdf)[[code]](https://github.com/zhaochen0110/LMLM) In **EMNLP'22**. (**CCF B**) 
* [**COLING-22**] Dan Qiao, Chenchen Dai, Yuyang Ding, **Juntao Li<sup>#</sup>**, Qiang Chen, Wenliang Chen and Min Zhang. SelfMix: Robust Learning Against Textual Label Noise with Self-Mixup Training. In **COLING'22**. (**Oral**) [[pdf]](https://arxiv.org/pdf/2210.04525.pdf)[[code]](https://github.com/noise-learning/SelfMix) (**CCF B**) 
* [**EMNLP-20**] Hai Ye, Qingyu Tan, Ruidan He, **Juntao Li**, Hwee Tou Ng, Lidong Bing.  Feature Adaptation of Pre-Trained Language Models across Languages and Domains with Robust Self-Training. In **EMNLP'20**. Full paper. [[pdf]](https://aclanthology.org/2020.emnlp-main.599.pdf)[[code]]((https://github.com/oceanypt/CFd)) (**CCF B**) 
* [**IJCAI-20**] **Juntao Li**, Ruidan He, Hai Ye, Hwee Tou Ng, Lidong Bing, and Rui Yan. Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model. In **IJCAI-PRICAI'20**. Full paper. [[pdf]](./IJCAI__PRICAI__2020.pdf) [[code]](https://github.com/lijuntaopku/UFD)(**CCF A**)
  
#### 2.2 Natural Language Generation
* [**TPAMI**] Yisheng Xiao, Lijun Wu, Junliang Guo, **Juntao Li<sup>#</sup>**, Min Zhang, Tao Qin, Tie-yan Liu. A Survey on Non-Autoregressive Generation for Neural Machine Translation and Beyond. **TPAMI**. [[pdf]](https://arxiv.org/pdf/2204.09269.pdf) (**CCF A**)
* [**WSDM-24**] Yue Wang, Zilong Zheng, Zecheng Tang, **Juntao Li<sup>#</sup>**, Zhihui Liu, Kunlong Chen, Jinxiong Chang, Qishen Zhang, Zhongyi Liu, Min Zhang. Towards Better Chinese Spelling Check for Search Engines: A New Dataset and Strong Baseline. **WSDM 2024**. [[pdf]]()(**CCF B**)
* [**NeurIPS-23**] Tong Wu, Zhihao Fan, Xiao Liu, Yeyun Gong, Yelong Shen, Jian Jiao, Hai-Tao Zheng, Juntao Li, Zhongyu Wei, Jian Guo, Nan Duan, Weizhu Chen. AR-Diffusion: Auto-Regressive Diffusion Model for Text Generation. **WSDM 2024**. [[pdf]]()(**CCF A**)
* [**ACL-23**] Xiaobo Liang, Zecheng Tang, **Juntao Li<sup>#</sup>**, Min Zhang. Open-ended Long Text Generation via Masked Language Modeling. [[pdf]](https://aclanthology.org/2023.acl-long.13.pdf)[[code]](https://github.com/dropreg/OpenLTG-MLM) **ACL 2023** (**CCF A**) 
* [**ACL-23**] Xiaobo Liang, **Juntao Li<sup>#</sup>**, Lijun Wu, Ziqiang Cao and Min Zhang. Dynamic and Efficient Inference for Text Generation via BERT Family. [[pdf]](https://aclanthology.org/2023.acl-long.162.pdf)[[code]](https://github.com/dropreg/DEER) **ACL 2023** (**CCF A**) 
* [**ACL-23**] Yue Wang, Dan Qiao, **Juntao Li<sup>#</sup>**, Jinxiong Chang, Qishen Zhang, Zhongyi Liu, Guannan Zhang and Min Zhang. Towards Better Hierarchical Text Classification with Data Generation. [[pdf]](https://aclanthology.org/2023.findings-acl.489.pdf)[[code]](https://github.com/wangyuenlp/Data-Generation-for-HTC) **ACL 2023 Findings** 
* [**ACL-23**] Zecheng Tang, Pinzheng Wang, Keyan Zhou, **Juntao Li<sup>#</sup>**, Ziqiang Cao and Min Zhang. Can Diffusion Model Achieve Better Performance in Text Generation ? Bridging the Gap between Training and Inference! [[pdf]](https://arxiv.org/pdf/2305.04465.pdf)[[code]](https://github.com/CODINNLG/Bridge_Gap_Diffusion) **ACL 2023 Findings** 
* [**AAAI-23**] Pei Guo, Yisheng Xiao, **Juntao Li<sup>#</sup>**, Lijun Wu, Min Zhang. RenewNAT: Renewing Potential Translation for
Non-Autoregressive Transformer. [[pdf]](https://arxiv.org/pdf/2303.07665.pdf)[[code]](https://github.com/AllForward/RenewNAT) In **AAAI'23** (**CCF A**)  
* [**AAAI-23**] Yisheng Xiao, Lijun Wu, Ruiyang Xu, **Juntao Li<sup>#</sup>**, Tao Qin, Tie-yan Liu, Min Zhang. AMOM: Adaptive Masking over Masking for Conditional Masked Language Model. [[pdf]](https://ojs.aaai.org/index.php/AAAI/article/download/26615/26387)[[code]](https://github.com/amom-nar/AMOM) In **AAAI'23** (**CCF A**) 
* [**NeurIPS-21**] Xiaobo Liang, Lijun Wu, **Juntao Li<sup>#</sup>**, Yue Wang, Qi Meng, Wei Chen, Tao Qin, Min Zhang, Tie-yan Liu.  R-Drop: Regularized Dropout for Neural Networks.In **NeurIPS'21**. Full paper. [[pdf]](https://arxiv.org/abs/2106.14448)[[code]](https://github.com/dropreg/R-Drop) (**CCF A**)    
* [**AAAI-21**] Meng-Hsuan Yu, **Juntao Li<sup>*</sup>**, Zhangming Chan, Dongyan Zhao and Rui Yan. Content Learning with Structure-Aware Writing: A Graph-Infused Dual Conditional Variational Autoencoder for Automatic Storytelling. In **AAAI'21**. Full paper. [[pdf]](https://ojs.aaai.org/index.php/AAAI/article/download/16751/16558) (**CCF A**)
* [**AAAI-20**] **Juntao Li**, Chang Liu, Jian Wang, Lidong Bing, Hongsong Li, Xiaozhong Liu, Dongyan Zhao and Rui Yan. Cross-Lingual Low-Resource Set-to-Description Retrieval for Global E-Commerce. In **AAAI'20**. Full paper. [[pdf]](./AAAI20.pdf) (**CCF A**)
* [**AAAI-20**] Meng-Hsuan Yu, **Juntao Li<sup>*</sup>**, Danyang Liu, Bo Tang, Haisong Zhang, Dongyan Zhao and Rui Yan. Draft and Edit: Automatic Storytelling Through Multi-Pass Hierarchical Conditional Variational Autoencoder. In **AAAI'20**. Full paper. [[pdf]](https://www.aaai.org/Papers/AAAI/2020GB/AAAI-YuM.8133.pdf) (**CCF A**)
* [**AAAI-20**] Danyang Liu, **Juntao Li<sup>*</sup>**, Meng-Hsuan Yu, Ziming Huang, Gongshen Liu, Dongyan Zhao and Rui Yan. A Character-Centric Neural Model for Automated Story Generation. In **AAAI'20**. Full paper. [[pdf]](https://www.aaai.org/Papers/AAAI/2020GB/AAAI-LiuD.%206731.pdf) (**CCF A**)
* [**AAAI-19**] **Juntao Li**, Lidong Bing, Lisong Qiu, Dongmin Chen, Dongyan Zhao and Rui Yan. Learning to Write Creative Stories with Thematic Consistency. In **AAAI'19**. Full paper. [[pdf]](https://www.aaai.org/ojs/index.php/AAAI/article/view/3993) (**CCF A**)
* [**EMNLP-18**] **Juntao Li**, Yan Song, Haisong Zhang, Dongmin Chen, Shuming Shi, Dongyan Zhao, and Rui Yan. Generating Classical Chinese Poems via Conditional Variational Autoencoder and Adversarial Training. In **EMNLP'18**. Full paper. [[pdf]](https://www.aclweb.org/anthology/D18-1423.pdf) (**CCF B**)


#### 2.3 Dialogue Systems
* [**FnTIR**] Rui Yan, **Juntao Li<sup>#</sup>**, Zhou Yu. Deep Learning for Dialogue System: Chit-Chat and Beyond. **Foundations and Trends® in Information Retrieval**. 2022, [[pdf]](./INR-083.pdf) (**SCI Q1, IF=8.0, 129 pages + 42 pages references**)
* [**ACL-23**] Chongyang Tao, Jiazhan Feng, Tao Shen, Chang Liu, **Juntao Li**, Xiubo Geng, Daxin Jiang. CORE: Cooperative Training of Retriever-Reranker for Effective Dialogue Response Selection. [[pdf]](https://aclanthology.org/2023.acl-long.174.pdf) **ACL 2023** (**CCF A**) 
* [**TOIS-21**] **Juntao Li**, Chang Liu, Chongyang Tao, Zhangming Chan, DongyanZhao, Min Zhang, Rui Yan. Dialog History Matters! Personalized Response Selection in Multi-turn Retrieval-based Chatbots. **TOIS,2021** [[pdf]](https://arxiv.org/pdf/2103.09534.pdf) (**CCF A**)
* [**ACL-19**] Lisong Qiu, **Juntao Li**, Wei Bi, Dongyan Zhao and Rui Yan. Are Training Samples Correlated? Learning to Generate Dialogue Responses with Multiple References. In **ACL'19**. Full paper. [[pdf]](https://www.aclweb.org/anthology/P19-1372.pdf) (**CCF A**)
* [**AAAI-19**] **Juntao Li**, Lisong Qiu, Bo Tang, Dongmin Chen, Dongyan Zhao and Rui Yan. Insufficient Data Can Also Rock! Learning to Converse Using Smaller Data with Augmentation. In **AAAI'19**. Full paper. [[pdf]](https://wvvw.aaai.org/ojs/index.php/AAAI/article/view/4641) (**CCF A**)
* [**EMNLP-19**] Zhangming Chan, **Juntao Li<sup>*</sup>**, Xiaopeng Yang, Xiuying Chen, Wenpeng Hu, Dongyan Zhao, and Rui Yan. Modeling Personalization in Continuous Space for Response Generation via Augmented Wasserstein Autoencoders. In **EMNLP'19**. Full paper. [[pdf]](https://www.aclweb.org/anthology/D19-1201.pdf) (**CCF B**)


### 3. Grants
* 第九届中国科协青年人才托举工程项目, PI
* National Science Foundation of China, No. 62206194, PI
* Natural Science Foundation of Jiangsu Province, No. BK20220488, PI
* Alibaba Innovation Research Grant, Co-PI
* Wudao Open Fund (BAAI), PI

### 4. Experiences
* Microsoft Research Aisa （2023/03-2023/06） <br>
* National University of Singapore （2019/09-2020/02） <br>
* Alibaba Damo Academy (2018/11-2019/06)<br>
* Tencent AI Lab (2018/04-2018/06)<br>
* Georgia Institute of Technology (2014/01-2014/05)

### 5. Tutorials and Talks
* **Juntao Li** and Rui Yan. Creative and Artistic Writing via Text Generation. In **AAAI'20**. Tutorial. [[Slide](https://lijuntaopku.github.io/AAAI2020-tutorial/AAAI20-tutorial.pdf)]. (**CCF A**)
* **Juntao Li** and Rui Yan. Creative and Artistic Writing via Text Generation. In **IJCAI'19**. Tutorial. [[Slide](https://lijuntaopku.github.io/ijcai2019tutorial/ijcai-tutorial.pdf)]. (**CCF A**)
* YSSNLP2022, Deep Learning for Dialogue System: Chit-Chat and Beyond, [[video]](https://event.baai.ac.cn/event/408)[[Slide]](./yssnlp22.pdf)

### 6. Alumni
* Chenchen Dai (Undergraduate student of Soochow University > Algorithm Engineer, Ant Group(蚂蚁金服，算法工程师))
* Yi Deng (Undergraduate student of Soochow University > University College London (UCL), Master)

### 7. Selected Awards
* Startrack Visiting Scholars (铸星计划), Microsoft Research Aisa
* Outstanding Graduates Awards (优秀毕业生), Peking University
* AAAI Tutorial Grant<br>
* National Scholarship (国家奖学金), Peking University<br>
* Pacemaker to Merit Student (三好学生标兵), Peking University<br>


### 8 Academic Services (Program Committee or Reviewer)
* ACL Rolling (Area Chair/Action Editor)
* 2023: ICLR, IJCAI (Senior PC), AACL (Website chair)
* 2022: AAAI, IJCAI, NAACL, KDD, ICLR, EMNLP (Area Chair)
* 2021: AAAI, IJCAI (Senior PC), NAACL-HLT, EACL, ACL (Area Chair), ICONIP (Tutorial, Session Chair)
* 2020: ACL, AAAI, COLING, EMNLP, AACL, CCL
* IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI/PAMI) 
* IEEE Transactions on Neural Networks and Learning Systems (TNNLS),
* Computational Linguistics (CL)<br>
* Transactions on Knowledge and Data Engineering (TKDE)<br>











